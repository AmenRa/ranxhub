ranxhub-id: msmarco-passage/dev/ranxhub/distilsplade-max
run:
  name: DistilSPLADE-max
  version: 1.0
  description: DistilSPLADE-max run reproduced using Pyserini.
  code: https://github.com/castorini/pyserini
  authors:
  - name: Elias Bassani
    orcid: 0000-0001-7922-2578
  team:
  - name: ranxhub
    url: https://github.com/AmenRa/ranxhub
  tags:
  - Retrieval
  date:
    day: 25
    month: May
    year: 2023
  results:
    MRR@10: 0.36843214172010735
    MAP@1000: 0.37456825687555095
    Recall@1000: 0.9787249283667622
benchmark:
  name: MSMARCO
  dataset: Passage
  split: Dev
  version: 1.0
  ir-datasets-id: msmarco-passage/dev/small
model:
  name: DistilSPLADE-max
  description: Sparse representation model built by refining SPLADE with MAX pooling
    and knowledge distillation.
  paper: 'SPLADE v2: Sparse Lexical and Expansion Model for Information Retrieval'
  doi: 10.48550/arXiv.2109.10086
  dblp: https://dblp.uni-trier.de/rec/journals/corr/abs-2109-10086.html?view=bibtex
  authors:
  - name: Thibault Formal
    orcid: ''
  - name: Carlos Lassance
    orcid: ''
  - name: Benjamin Piwowarski
    orcid: 0000-0001-6792-3262
  - name: "St\xE9phane Clinchant"
    orcid: ''
  tags:
  - Sparse Representation
  - Knowledge Distillation
